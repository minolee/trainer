

model_name: midm_r1_zero
base_trainer: GRPOTrainer

reader:
  sources:
    - source: AI-MO/NuminaMath-TIR
      use_cache: true
      reader: reader.read_sol

format: reader.format_conversation

model: 
  path: Qwen/Qwen2.5-1.5B-Instruct
  torch_dtype: bfloat16
  attn_implementation: flash_attention_2


# GRPO trainer config
training_arguments:
  bf16: true
  use_vllm: false
  vllm_device: auto
  vllm_gpu_memory_utilization: 0.7
  do_eval: true
  eval_strategy: steps
  eval_steps: 100
  gradient_accumulation_steps: 16
  gradient_checkpointing: true
  gradient_checkpointing_kwargs:
    use_reentrant: false
  learning_rate: 2.0e-05
  log_level: info
  logging_steps: 5
  logging_strategy: steps
  lr_scheduler_type: cosine
  max_prompt_length: 512
  max_completion_length: 1024
  max_steps: -1
  num_generations: 2
  num_train_epochs: 1
  overwrite_output_dir: true
  per_device_eval_batch_size: 4   
  per_device_train_batch_size: 2
  report_to:
  - wandb
  save_strategy: "no"
  seed: 42
  warmup_ratio: 0.1
