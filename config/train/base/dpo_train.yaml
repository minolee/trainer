
model_name: test_gpt2_dpo
base_trainer: DPOTrainer
reader:
  sources:
    - name: test
      source: rsc/data/preference/processed/dpo_1cycle_241016.jsonl
      split: train
      limit: 500
      reader: read_preference

format: format_preference

# dataloader:
#   shuffle: true
#   num_workers: 0
  # collate_fn: preference_collate_fn

model:
  path: Qwen/Qwen2-0.5B-Instruct
  device: cpu


optimizer:
  name: adamw_hf
  learning_rate: 5.0e-05
  weight_decay: 0.01

scheduler:
  name: linear
  warmup_ratio: 0.1

training_arguments:
  num_train_epochs: 1
  gradient_accumulation_steps: 4
  per_device_train_batch_size: 8