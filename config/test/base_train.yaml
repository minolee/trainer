
model_name: test_gpt2
reader_config:
  sources:
    - name: test
      source: rsc/data/AiHub-Largeai_SFT_QA.jsonl
      split:
        type: train
      reader: read_simple

dataset_config:
  prompt: llama31
  dataset: BaseDataset

dataloader_config:
  shuffle: false
  num_workers: 0 # currently not working with num_workers > 0
  batch_size: 4
tokenizer_config:
  from_pretrained: openai-community/gpt2

model_load_config:
  base_config: openai-community/gpt2
  device: mps


loss_config:
  name: CrossEntropyLoss
  ignore_index: -100

optimizer_config:
  name: AdamW
  lr: 5e-5
  weight_decay: 0.01

scheduler_config:
  name: WarmupLinearSchedule
  warmup_steps: 100
  t_total: 1000

trainer_config:
  num_train_epochs: 3
